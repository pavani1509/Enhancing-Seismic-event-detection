# -*- coding: utf-8 -*-
"""Earthquake detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1khLYG8H9ghJZXHdZft1rzAG9b79qXu9y
"""

!pip install gradio

## Main code

import numpy as np
import pandas as pd
import gradio as gr
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, LSTM
from tensorflow.keras.optimizers import Adam

# Global variable to store the test accuracy
test_accuracy = None

# Load your waveform data CSV file
df = pd.read_csv('Indian subcontinent.csv')

# Use 'mag' as a feature
df['Earthquake'] = (df['mag'] > 5.5).astype(int)

# Normalize the 'mag' column
df['mag'] = (df['mag'] - df['mag'].min()) / (df['mag'].max() - df['mag'].min())

# Create input sequences for the model
def create_sequences(data, seq_length):
    xs, ys = [], []
    for i in range(len(data) - seq_length):
        x = data.iloc[i:(i + seq_length)][['mag']].values
        y = data.iloc[i + seq_length]['Earthquake']
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

SEQ_LENGTH = 50
X, y = create_sequences(df, SEQ_LENGTH)

# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Reshape the data to match Conv1D input requirements (samples, time steps, features)
X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

# Build the model including Conv1D and LSTM layers
model = Sequential()

# Conv1D layers
model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(SEQ_LENGTH, 1)))
model.add(MaxPooling1D(pool_size=2))

# LSTM layer
model.add(LSTM(128, return_sequences=False))

# Dense layers
model.add(Dense(100, activation='relu'))
model.add(Dense(50, activation='relu'))
model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))

# Evaluate the model and store the test accuracy
loss, accuracy = model.evaluate(X_test, y_test)
test_accuracy = accuracy * 100  # Convert to percentage

# Function to classify a waveform based on magnitude
def classify_waveform_based_on_magnitude(waveform):
    # Count occurrences in different magnitude ranges
    noise_count = np.sum(waveform < 2)
    minor_eq_count = np.sum((waveform >= 2) & (waveform < 5))
    major_eq_count = np.sum((waveform >= 5) & (waveform <= 6))
    strong_eq_count = np.sum(waveform > 6)

    # Determine the classification based on the majority count
    if noise_count == len(waveform):  # If all values are noise
        return "Noise"
    elif noise_count > max(minor_eq_count, major_eq_count, strong_eq_count):
        return "Noise"
    elif minor_eq_count > max(major_eq_count, strong_eq_count):
        return "Minor Earthquake"
    elif major_eq_count > max(minor_eq_count, strong_eq_count):
        return "Major Earthquake"
    else:
        return "Strong Earthquake"

# Gradio function to handle CSV file input and classify the waveform
def classify_from_csv(file):
    # Read the CSV file into a DataFrame
    df = pd.read_csv(file.name)

    # Check if 'mag' column exists
    if 'mag' not in df.columns:
        return "Error: CSV file must contain a 'mag' column."

    # Extract the 'mag' column as a numpy array
    waveform = df['mag'].values

    # Ensure there are at least 30 values in the 'mag' column
    if len(waveform) < 30:
        return "Error: The 'mag' column must contain at least 30 values."

    # # Consider only the first 30 values for classification
    # waveform = waveform[:30]

    # Classify the waveform
    classification = classify_waveform_based_on_magnitude(waveform)

    # Return classification result and test accuracy
    return f"Classification: {classification}\nTest Accuracy: {test_accuracy:.2f}%"
# Define the custom CSS to add a background image
custom_css = """
body {
    background-image: url('http://getwallpapers.com/wallpaper/full/4/a/5/830758-best-earthquake-wallpapers-2880x1800.jpg');
    background-size: cover;
    background-position: center;
}
"""
# Gradio interface with file input for CSV
interface = gr.Interface(
    fn=classify_from_csv,
    inputs=gr.File(label="Upload CSV File"),
    outputs="text",
    css=custom_css,
    title="Earthquake Waveform Classifier",
    description="Upload a CSV file containing a 'mag' column with at least 30 magnitude values.\nThe classifier will output 'Noise', 'Minor Earthquake', 'Major Earthquake', or 'Strong Earthquake' based on the magnitudes, along with the test accuracy."
)

# Launch the Gradio interface
interface.launch()

"""# New Section"""